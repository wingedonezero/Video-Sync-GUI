# vsg_core/subtitles/cleanup.py
# -*- coding: utf-8 -*-
from __future__ import annotations
import re
from pathlib import Path
from collections import defaultdict
import pysubs2
import enchant

class SubtitleCleaner:
    """
    Cleans and analyzes SRT files generated by an OCR process,
    applying specific, dictionary-guarded fixes and reporting on potential issues.
    """
    def __init__(self, subtitle_path: str, config: dict, custom_wordlist: set = None):
        self.path = Path(subtitle_path)
        self.config = config
        self.subs = pysubs2.load(subtitle_path, encoding='utf-8')
        self.report = defaultdict(int)

        try:
            self.dictionary = enchant.Dict("en_US")
            if custom_wordlist:
                for word in custom_wordlist:
                    self.dictionary.add_to_session(word)
        except enchant.errors.DictNotFoundError:
            self.dictionary = None
            log_func = getattr(self, 'runner._log_message', print)
            log_func("[WARN] OCR Cleanup: 'en_US' dictionary not found. Disabling dictionary guard.")


    def cleanup(self) -> dict:
        """
        Runs the full cleanup and analysis process on the loaded subtitle file.
        Returns a dictionary containing the report of all changes and findings.
        """
        standalone_l_re = re.compile(r'\bl\b')
        i_in_word_re = re.compile(r'(?<=[a-z])I(?=[a-z])')
        space_before_punct_re = re.compile(r'\s+([!?])')

        for line in self.subs:
            original_text = line.text
            words = original_text.split()
            modified_words = []
            text_was_modified = False

            for word in words:
                cleaned_word = re.sub(r'[.,?!"\'”’\)\]]+$', '', word)

                # *** THE FIX IS HERE ***
                # Add a guard to skip empty strings after cleaning.
                if not cleaned_word:
                    modified_words.append(word)
                    continue

                if self.dictionary and self.dictionary.check(cleaned_word):
                    modified_words.append(word)
                    self.report['words_shielded_by_dict'] += 1
                    continue

                if cleaned_word.endswith('ll'):
                    modified_word = re.sub(r'll$', '!!', word)
                    modified_words.append(modified_word)
                    self.report['fixed_trailing_ll'] += 1
                    text_was_modified = True
                elif cleaned_word.endswith('l'):
                    modified_word = re.sub(r'l$', '!', word)
                    modified_words.append(modified_word)
                    self.report['fixed_trailing_l'] += 1
                    text_was_modified = True
                else:
                    modified_words.append(word)

            if text_was_modified:
                text = " ".join(modified_words)
            else:
                text = original_text

            # --- Apply Other Fixes ---
            text, count = standalone_l_re.subn('I', text)
            if count > 0: self.report['fixed_standalone_l_to_i'] += count

            text, count = i_in_word_re.subn('l', text)
            if count > 0: self.report['fixed_i_in_word_to_l'] += count

            text, count = space_before_punct_re.subn(r'\1', text)
            if count > 0:
                if '!' in text: self.report['removed_space_before_bang'] += text.count(' !')
                if '?' in text: self.report['removed_space_before_qmark'] += text.count(' ?')

            if self.config.get('ocr_cleanup_normalize_ellipsis', False):
                text, count = re.subn('…', '...', text)
                if count > 0: self.report['normalized_ellipsis'] += count

            line.text = text

            # --- Generate Flags/Reports ---
            if text.count('"') % 2 != 0 or text.count("'") % 2 != 0:
                self.report['quote_balance_warnings'] += 1
            if '|' in text: self.report['stray_pipes'] += 1

        self.subs.save(str(self.path), encoding='utf-8')
        return dict(self.report)

def run_cleanup(subtitle_path: str, config: dict, runner) -> dict:
    """
    Public function to instantiate and run the cleaner.
    """
    try:
        custom_wordlist = set()
        wordlist_path_str = config.get('ocr_cleanup_custom_wordlist_path')
        if wordlist_path_str:
            wordlist_path = Path(wordlist_path_str)
            if wordlist_path.is_file():
                try:
                    with open(wordlist_path, 'r', encoding='utf-8') as f:
                        custom_words = {line.strip() for line in f if line.strip()}
                    custom_wordlist = custom_words
                    runner._log_message(f"[OCR Cleanup] Loaded {len(custom_wordlist)} words from custom wordlist.")
                except Exception as e:
                    runner._log_message(f"[WARN] OCR Cleanup: Could not read custom wordlist file at '{wordlist_path}': {e}")
            else:
                runner._log_message(f"[WARN] OCR Cleanup: Custom wordlist file not found at '{wordlist_path}'.")

        cleaner = SubtitleCleaner(subtitle_path, config, custom_wordlist=custom_wordlist)
        cleaner.runner = runner
        report = cleaner.cleanup()
        runner._log_message(f"[OCR Cleanup] Cleaned '{Path(subtitle_path).name}'.")
        return report
    except Exception as e:
        runner._log_message(f"[OCR Cleanup] ERROR: Failed to process '{Path(subtitle_path).name}': {e}")
        return {}
